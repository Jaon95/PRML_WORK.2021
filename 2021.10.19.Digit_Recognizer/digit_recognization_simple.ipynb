{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 导入必要的包\n","from sklearn import neural_network\n","from sklearn import metrics\n","from sklearn import model_selection\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split\n","import itertools\n","import pandas as pd\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import seaborn as sns\n","%matplotlib inline\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class NetualNetworkModelFactory:\n","\n","    def __sigmod(self, z):\n","        z_shape = z.shape\n","        z = z.ravel()\n","        temp = []\n","        for i in range(len(z)):\n","            if z[i] >= 0:\n","                s = 1/(1+np.exp(-z[i]))\n","                temp.append(s)\n","            else:\n","                s = np.exp(z[i])/(1+np.exp(z[i]))\n","                temp.append(s)\n","        return np.array(temp).reshape(z_shape)\n","    _active_function = __sigmod\n","\n","\n","    @property\n","    def active_function(self):\n","        return self._active_function\n","\n","    @active_function.setter\n","    def active_function(self, value):\n","        self._active_function = value\n","\n","    @property\n","    def params(self):\n","        return self._params\n","\n","    @params.setter\n","    def params(self, value):\n","        self._params = value\n","    \n","    @property\n","    def alpha(self):\n","        return self._alpha\n","    \n","    @alpha.setter\n","    def alpha(self,value):\n","        self._alpha =value\n","    \n","\n","    # 定义结构\n","    def __network_architecture(self, X, Y):\n","        n_x = X.shape[0]  # x作为输入时，已经转置，所以这里的n_x = 784\n","\n","        n_h = 10\n","\n","        n_y = Y.shape[0]  # y作为输入时，已经转置，所以这里的n_y为1\n","        # 整个网络的输入节点有n_x(784)个，输出有n_y(1)个\n","        return (n_x, n_h, n_y)\n","\n","    # 初始化各个参数\n","    def __network_parameters(self, n_x, n_h, n_y):\n","        # 每个节点都要一组w，所有有n_h组w，每个w有n_x个参数,这里就有10组w，每组w有784个参数\n","        W1 = np.random.randn(n_h, n_x)*0.01\n","        b1 = np.random.randn(n_h, 1)\n","        # 每y节点都要一组w，所有有n_y组w，每个w有n_h个参数，这里就是1组w，共10个参数\n","        W2 = np.random.randn(n_y, n_h)*0.01\n","        b2 = np.random.randn(n_y, 1)\n","        return {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2}\n","\n","    # 运算\n","    def __forward_propagation(self, X, params):\n","        # W1:10*784，784*样本个数，10*1 = 10*样本个数\n","        Z1 = np.dot(params['W1'], X)+params['b1']\n","        A1 = self._active_function(Z1)  # 10*样本个数，对每个进行计算\n","\n","        Z2 = np.dot(params['W2'], A1)+params['b2']  # 1*10 10*样本个数,b2:1*1\n","        A2 = self._active_function(Z2)  # A2: 1*样本个数\n","        return {'Z1': Z1, 'A1': A1, 'Z2': Z2, 'A2': A2}\n","\n","    # 计算误差\n","    def __compute_error(self, predict, actual):\n","        logprobs = np.multiply(np.log(predict), actual) + \\\n","            np.multiply(np.log(1-predict), actual)\n","        cost = -np.sum(logprobs)/actual.shape[1]  # actual的列的个数，也就是样本数\n","        return cost\n","\n","    # 定义误差反馈，并计算参数变化增量\n","    def __backward_propagation(self, params, activations, X, Y):\n","        m = X.shape[1]  # 样本个数\n","\n","        # output layer\n","        dZ2 = activations['A2'] - Y  # compute the error derivative ：1*样本个数\n","        # compute the weight derivative 1*样本个数  样本个数*10, 每个样本的A1，结果就是将每个样本的误差*每个样本对应的A1.\n","        dW2 = np.dot(dZ2, activations['A1'].T) / m\n","        # compute the bias derivative,计算输出层的总误差，设置为b2的调整量\n","        db2 = np.sum(dZ2, axis=1, keepdims=True)/m\n","\n","        # hidden layer\n","        # 10*1,1*样本数量=10*样本数量，得出每个样本在隐藏层的误差，1-np.power(activations['A1'], 2)\n","        dZ1 = np.dot(params['W2'].T, dZ2)*(1-np.power(activations['A1'], 2))\n","        # 10*样本数量 样本数量*训练参数个数 = 10*训练参数个数（也就是输入层的节点数量）然后/m，得到对每个dw1的调整\n","        dW1 = np.dot(dZ1, X.T)/m\n","        # compute the bias derivative,计算输出层的总误差，设置为b1的调整量\n","        db1 = np.sum(dZ1, axis=1, keepdims=True)/m\n","\n","        return {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n","\n","    # 更新参数\n","    def __update_parameters(self, params, derivatives, alpha=1.2):\n","        # alpha is the model's learning rate\n","\n","        params['W1'] = params['W1'] - alpha * derivatives['dW1']\n","        params['b1'] = params['b1'] - alpha * derivatives['db1']\n","        params['W2'] = params['W2'] - alpha * derivatives['dW2']\n","        params['b2'] = params['b2'] - alpha * derivatives['db2']\n","        return params\n","\n","    # 开始训练\n","    def fit(self, X, Y, n_h, num_iterations=100):\n","        n_x = self.__network_architecture(X, Y)[0]  # 获取到了x的节点个数，也就是输入\n","        n_y = self.__network_architecture(X, Y)[2]  # 获取了y的节点个数，也就是输出\n","\n","        params = self.__network_parameters(n_x, n_h, n_y)  # 对所有的参数进行初始化\n","        for i in range(0, num_iterations):\n","            results = self.__forward_propagation(X, params)\n","            error = self.__compute_error(results['A2'], Y)\n","            derivatives = self.__backward_propagation(params, results, X, Y)\n","            params = self.__update_parameters(params, derivatives)\n","        self.params = params\n","\n","    def predict(self, X):\n","        results = self.__forward_propagation(X, self.params)\n","        print(results['A2'][0])\n","        predictions = np.around(results['A2'])\n","        return predictions\n","\n","    def score(self, x, y):\n","        predictions = self.predict(x)\n","        score = float((np.dot(y, predictions.T) +\n","                       np.dot(1-y, 1-predictions.T))/float(y.size)*100)\n","        print('Accuracy: %d' % score + '%')\n","        return score\n","\n","    def plot_confusion_matrix(self, cm, classes,\n","                              normalize=False,\n","                              title='Confusion matrix',\n","                              cmap=plt.cm.Blues):\n","        \"\"\"\n","        This function prints and plots the confusion matrix.\n","        Normalization can be applied by setting `normalize=True`.\n","        \"\"\"\n","\n","        # 设定图片有多少行，多少列，用于后面向每个格子中填充数据\n","        plt.imshow(cm, cmap=cmap)  # 四舍五入 interpolation='nearest'\n","\n","        # 设置标题，以及颜色条\n","        plt.title(title)\n","        plt.colorbar()\n","\n","        # 分为设置x方向和y方向有多少个分类，以及每个分类显示的名称\n","        tick_marks = np.arange(len(classes))\n","        plt.xticks(tick_marks, classes, rotation=0)\n","        plt.yticks(tick_marks, classes)\n","\n","        # 判断是否需要归一化\n","        if normalize:\n","            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","        thresh = cm.max() / 2.\n","        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","            plt.text(j, i, cm[i, j],\n","                     horizontalalignment=\"center\",\n","                     color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","        plt.tight_layout()\n","        plt.ylabel('True label')\n","        plt.xlabel('Predicted label')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train = pd.read_csv(\"train.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# sns.countplot(train['label'])\n","# 我们也可以使用直方图来画\n","# plt.hist(train['label'],10)\n","# plt.show()\n","# fig,ax = plt.subplots()\n","# n,bins,patches = ax.hist(train['label'],10,edgecolor='w')\n","sns.countplot(train['label'])\n","# ax是基于坐标轴来处理数据的，所以有x、y相关的设置属性"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Check for null and missing values\n","train.isnull()  # 判断整个矩阵的每个单元格的是否null，若是则返回True\n","train.isnull().any(axis=1).describe()\n","# isnull用来判断每个元素是否nan，none，nat类型，若是，则判断为true，any类似于或操作"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# include only the rows having label = 0 or 1 (binary classification)\n","# 本次训练只训练 分类为0或者1的\n","X = train[train['label'].isin([0, 1])]\n","# target variable\n","Y = train[train['label'].isin([0, 1])]['label']\n","# remove the label from X\n","# drop删除指定的数据，axi=1代表按照列删除,若是没有指定，则需要输入行索引，按照行来删除\n","X = X.drop(['label'], axis=1)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 训练集和测试集的划分\n","x_train, x_test, y_train, y_test = model_selection.train_test_split(\n","    X, Y, random_state=100, test_size=0.3)\n","x_train = x_train.T.values\n","y_train = y_train.values.reshape(1, y_train.size)\n","x_test = x_test.T.values\n","y_test = y_test.values.reshape(1, y_test.size)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('下面是节点为：100，迭代次数为：10的训练,使用sigmod函数')\n","model = NetualNetworkModelFactory()\n","model.fit(x_train, y_train, n_h=100, num_iterations=10)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('------训练集------')\n","model.score(x_train, y_train)\n","confusion_mtx = confusion_matrix(model.predict(\n","    x_train).reshape(-1, 1), y_train.reshape(-1, 1))\n","classes = range(2)\n","model.plot_confusion_matrix(confusion_mtx, classes=classes)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('-----测试集------')\n","model.score(x_test, y_test)\n","confusion_mtx = confusion_matrix(model.predict(\n","    x_test).reshape(-1, 1), y_test.reshape(-1, 1))\n","model.plot_confusion_matrix(confusion_mtx, classes=classes)\n","\n","# # %%\n","# print('下面是节点为：100，迭代次数为：10的训练,使用tanh函数')\n","# model = NetualNetworkModelFactory()\n","# model.active_function = np.tanh\n","# model.fit(x_train, y_train, n_h=100, num_iterations=10)\n","# # %%\n","# print('------训练集------')\n","# model.score(x_train, y_train)\n","# confusion_mtx = confusion_matrix(model.predict(\n","#     x_train).reshape(-1, 1), y_train.reshape(-1, 1))\n","# classes = range(2)\n","# model.plot_confusion_matrix(confusion_mtx, classes=classes)\n","# #%%\n","# print('-----测试集------')\n","# model.score(x_test, y_test)\n","# confusion_mtx = confusion_matrix(model.predict(\n","#     x_test).reshape(-1, 1), y_test.reshape(-1, 1))\n","# model.plot_confusion_matrix(confusion_mtx, classes=classes)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('下面是节点为：10，迭代次数为：100 的训练，使用sigmod函数')\n","model = NetualNetworkModelFactory()\n","model.fit(x_train, y_train, n_h=10, num_iterations=100)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('------训练集------')\n","model.score(x_train, y_train)\n","confusion_mtx = confusion_matrix(model.predict(\n","    x_train).reshape(-1, 1), y_train.reshape(-1, 1))\n","classes = range(2)\n","model.plot_confusion_matrix(confusion_mtx, classes=classes)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('-----测试集------')\n","model.score(x_test, y_test)\n","confusion_mtx = confusion_matrix(model.predict(\n","    x_test).reshape(-1, 1), y_test.reshape(-1, 1))\n","model.plot_confusion_matrix(confusion_mtx, classes=classes)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('---------下面看看迭代次数对精度的影响-----------')\n","train_score = []\n","test_score = []\n","for i in range(10, 150):\n","    model = NetualNetworkModelFactory()\n","    model.fit(x_train, y_train, n_h=10, num_iterations=i)\n","    train_score.append(model.score(x_train, y_train))\n","    test_score.append(model.score(x_test, y_test))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, ax = plt.subplots()\n","ax.plot([i for i in range(10, 20)], train_score)\n","ax.plot([i for i in range(10, 20)], test_score)\n","ax.set_xlabel([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n","plt.show()"]}],"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
