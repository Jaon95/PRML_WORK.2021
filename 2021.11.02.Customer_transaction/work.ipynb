{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入需要的包\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "from sklearn import metrics\n",
    "import itertools\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA--exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       202\n",
       "unique        1\n",
       "top       False\n",
       "freq        202\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#检查是否有缺失值\n",
    "train.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.100490</td>\n",
       "      <td>10.679914</td>\n",
       "      <td>-1.627622</td>\n",
       "      <td>10.715192</td>\n",
       "      <td>6.796529</td>\n",
       "      <td>11.078333</td>\n",
       "      <td>-5.065317</td>\n",
       "      <td>5.408949</td>\n",
       "      <td>16.545850</td>\n",
       "      <td>0.284162</td>\n",
       "      <td>...</td>\n",
       "      <td>3.234440</td>\n",
       "      <td>7.438408</td>\n",
       "      <td>1.927839</td>\n",
       "      <td>3.331774</td>\n",
       "      <td>17.993784</td>\n",
       "      <td>-0.142088</td>\n",
       "      <td>2.303335</td>\n",
       "      <td>8.908158</td>\n",
       "      <td>15.870720</td>\n",
       "      <td>-3.326537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.300653</td>\n",
       "      <td>3.040051</td>\n",
       "      <td>4.050044</td>\n",
       "      <td>2.640894</td>\n",
       "      <td>2.043319</td>\n",
       "      <td>1.623150</td>\n",
       "      <td>7.863267</td>\n",
       "      <td>0.866607</td>\n",
       "      <td>3.418076</td>\n",
       "      <td>3.332634</td>\n",
       "      <td>...</td>\n",
       "      <td>4.559922</td>\n",
       "      <td>3.023272</td>\n",
       "      <td>1.478423</td>\n",
       "      <td>3.992030</td>\n",
       "      <td>3.135162</td>\n",
       "      <td>1.429372</td>\n",
       "      <td>5.454369</td>\n",
       "      <td>0.921625</td>\n",
       "      <td>3.010945</td>\n",
       "      <td>10.438015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>-15.043400</td>\n",
       "      <td>2.117100</td>\n",
       "      <td>-0.040200</td>\n",
       "      <td>5.074800</td>\n",
       "      <td>-32.562600</td>\n",
       "      <td>2.347300</td>\n",
       "      <td>5.349700</td>\n",
       "      <td>-10.505500</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.093300</td>\n",
       "      <td>-2.691700</td>\n",
       "      <td>-3.814500</td>\n",
       "      <td>-11.783400</td>\n",
       "      <td>8.694400</td>\n",
       "      <td>-5.261000</td>\n",
       "      <td>-14.209600</td>\n",
       "      <td>5.960600</td>\n",
       "      <td>6.299300</td>\n",
       "      <td>-38.852800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.453850</td>\n",
       "      <td>-4.740025</td>\n",
       "      <td>8.722475</td>\n",
       "      <td>5.254075</td>\n",
       "      <td>9.883175</td>\n",
       "      <td>-11.200350</td>\n",
       "      <td>4.767700</td>\n",
       "      <td>13.943800</td>\n",
       "      <td>-2.317800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058825</td>\n",
       "      <td>5.157400</td>\n",
       "      <td>0.889775</td>\n",
       "      <td>0.584600</td>\n",
       "      <td>15.629800</td>\n",
       "      <td>-1.170700</td>\n",
       "      <td>-1.946925</td>\n",
       "      <td>8.252800</td>\n",
       "      <td>13.829700</td>\n",
       "      <td>-11.208475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.524750</td>\n",
       "      <td>-1.608050</td>\n",
       "      <td>10.580000</td>\n",
       "      <td>6.825000</td>\n",
       "      <td>11.108250</td>\n",
       "      <td>-4.833150</td>\n",
       "      <td>5.385100</td>\n",
       "      <td>16.456800</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>...</td>\n",
       "      <td>3.203600</td>\n",
       "      <td>7.347750</td>\n",
       "      <td>1.901300</td>\n",
       "      <td>3.396350</td>\n",
       "      <td>17.957950</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>2.408900</td>\n",
       "      <td>8.888200</td>\n",
       "      <td>15.934050</td>\n",
       "      <td>-2.819550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.758200</td>\n",
       "      <td>1.358625</td>\n",
       "      <td>12.516700</td>\n",
       "      <td>8.324100</td>\n",
       "      <td>12.261125</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.102900</td>\n",
       "      <td>2.937900</td>\n",
       "      <td>...</td>\n",
       "      <td>6.406200</td>\n",
       "      <td>9.512525</td>\n",
       "      <td>2.949500</td>\n",
       "      <td>6.205800</td>\n",
       "      <td>20.396525</td>\n",
       "      <td>0.829600</td>\n",
       "      <td>6.556725</td>\n",
       "      <td>9.593300</td>\n",
       "      <td>18.064725</td>\n",
       "      <td>4.836800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.315000</td>\n",
       "      <td>10.376800</td>\n",
       "      <td>19.353000</td>\n",
       "      <td>13.188300</td>\n",
       "      <td>16.671400</td>\n",
       "      <td>17.251600</td>\n",
       "      <td>8.447700</td>\n",
       "      <td>27.691800</td>\n",
       "      <td>10.151300</td>\n",
       "      <td>...</td>\n",
       "      <td>18.440900</td>\n",
       "      <td>16.716500</td>\n",
       "      <td>8.402400</td>\n",
       "      <td>18.281800</td>\n",
       "      <td>27.928800</td>\n",
       "      <td>4.272900</td>\n",
       "      <td>18.321500</td>\n",
       "      <td>12.000400</td>\n",
       "      <td>26.079100</td>\n",
       "      <td>28.500700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target          var_0          var_1          var_2  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.100490      10.679914      -1.627622      10.715192   \n",
       "std         0.300653       3.040051       4.050044       2.640894   \n",
       "min         0.000000       0.408400     -15.043400       2.117100   \n",
       "25%         0.000000       8.453850      -4.740025       8.722475   \n",
       "50%         0.000000      10.524750      -1.608050      10.580000   \n",
       "75%         0.000000      12.758200       1.358625      12.516700   \n",
       "max         1.000000      20.315000      10.376800      19.353000   \n",
       "\n",
       "               var_3          var_4          var_5          var_6  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        6.796529      11.078333      -5.065317       5.408949   \n",
       "std         2.043319       1.623150       7.863267       0.866607   \n",
       "min        -0.040200       5.074800     -32.562600       2.347300   \n",
       "25%         5.254075       9.883175     -11.200350       4.767700   \n",
       "50%         6.825000      11.108250      -4.833150       5.385100   \n",
       "75%         8.324100      12.261125       0.924800       6.003000   \n",
       "max        13.188300      16.671400      17.251600       8.447700   \n",
       "\n",
       "               var_7          var_8  ...        var_190        var_191  \\\n",
       "count  200000.000000  200000.000000  ...  200000.000000  200000.000000   \n",
       "mean       16.545850       0.284162  ...       3.234440       7.438408   \n",
       "std         3.418076       3.332634  ...       4.559922       3.023272   \n",
       "min         5.349700     -10.505500  ...     -14.093300      -2.691700   \n",
       "25%        13.943800      -2.317800  ...      -0.058825       5.157400   \n",
       "50%        16.456800       0.393700  ...       3.203600       7.347750   \n",
       "75%        19.102900       2.937900  ...       6.406200       9.512525   \n",
       "max        27.691800      10.151300  ...      18.440900      16.716500   \n",
       "\n",
       "             var_192        var_193        var_194        var_195  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        1.927839       3.331774      17.993784      -0.142088   \n",
       "std         1.478423       3.992030       3.135162       1.429372   \n",
       "min        -3.814500     -11.783400       8.694400      -5.261000   \n",
       "25%         0.889775       0.584600      15.629800      -1.170700   \n",
       "50%         1.901300       3.396350      17.957950      -0.172700   \n",
       "75%         2.949500       6.205800      20.396525       0.829600   \n",
       "max         8.402400      18.281800      27.928800       4.272900   \n",
       "\n",
       "             var_196        var_197        var_198        var_199  \n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000  \n",
       "mean        2.303335       8.908158      15.870720      -3.326537  \n",
       "std         5.454369       0.921625       3.010945      10.438015  \n",
       "min       -14.209600       5.960600       6.299300     -38.852800  \n",
       "25%        -1.946925       8.252800      13.829700     -11.208475  \n",
       "50%         2.408900       8.888200      15.934050      -2.819550  \n",
       "75%         6.556725       9.593300      18.064725       4.836800  \n",
       "max        18.321500      12.000400      26.079100      28.500700  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe() #查看数据统计量信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 200)\n"
     ]
    }
   ],
   "source": [
    "X = train.iloc[:, 2:].values.astype('float64')\n",
    "Y = train['target'].values\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='count'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#检查样本是否平衡\n",
    "sns.countplot(Y, palette='Set1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20098"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y[Y==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义函数用来显示消耗的时间\n",
    "def show_time(values):\n",
    "    t = time.strftime('%H:%M:%S',time.gmtime(values))\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_metrics = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    # 设定图片有多少行，多少列，用于后面向每个格子中填充数据\n",
    "    plt.imshow(cm, cmap=cmap)  # 四舍五入 interpolation='nearest'\n",
    "\n",
    "    # 设置标题，以及颜色条\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    # 分为设置x方向和y方向有多少个分类，以及每个分类显示的名称\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    # 判断是否需要归一化\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. LR --- Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape of train: (140000, 200)\n",
      "data shape of test (60000, 200)\n",
      "fitting finished!\n",
      "time consumed of fitting: 00:01:51\n",
      "scoring finished!\n",
      "time consumed of scoring: 00:00:00\n",
      "test acc of logistics regression without PCA :  0.9146666666666666\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC is  0.1605062513428895\n"
     ]
    }
   ],
   "source": [
    "# 下面使用回归模型来进行数据预测和训练\n",
    "def logit_regresstion():\n",
    "    x_train, x_test, y_train, y_test = model_selection.train_test_split(X,Y,test_size=0.3,random_state=52)\n",
    "    \n",
    "    print('data shape of train:',x_train.shape)\n",
    "    print('data shape of test',x_test.shape)\n",
    "    model = LogisticRegression(C=9,dual=False,max_iter=x_train.shape[0])\n",
    "    start_time = time.time()\n",
    "    model.fit(x_train , y_train)\n",
    "    print('fitting finished!')\n",
    "    end_time = time.time()\n",
    "    fit_time = end_time- start_time\n",
    "    print('time consumed of fitting:',show_time(fit_time))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    score = model.score(x_test, y_test)\n",
    "    end_time = time.time()\n",
    "    score_time = end_time - start_time\n",
    "    print('scoring finished!')\n",
    "    print('time consumed of scoring:',show_time(score_time))\n",
    "    print('test acc of logistics regression without PCA : ',score)\n",
    "\n",
    "\n",
    "\n",
    "    #下面开始auc分析\n",
    "    # 计算测试集上面预测值的概率\n",
    "    pre_proba = model.predict_proba(x_test).max(axis=1)\n",
    "    fpr,tpr,thresholds = metrics.roc_curve(y_test,pre_proba)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.show()\n",
    "\n",
    "    auc = metrics.roc_auc_score(y_test,pre_proba)\n",
    "    print('Validation AUC is ',auc)\n",
    "    return [model,fit_time,score_time,score,auc]\n",
    "logit_metrics = logit_regresstion()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "降维后的数据训练数据 shape： (140000, 137)\n",
      "降维后的测试数据shape:  (60000, 137)\n",
      "fitting finished!\n",
      "time consumed of fitting: 00:00:00\n",
      "scoring finished!\n",
      "time consumed of scoring: 00:00:00\n",
      "test acc of logistics regression with PCA :  0.91305\n",
      "打印混淆矩阵。。。。。。\n",
      "\n",
      "[[179902  20098]\n",
      " [     0      0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#使用pca对feature进行降维后，再进行训练\n",
    "def logit_regresstion_with_pca():\n",
    "    x_train, x_test, y_train, y_test = model_selection.train_test_split(X,Y,test_size=0.3,random_state=52)\n",
    "\n",
    "    #标准化\n",
    "    std_scal = StandardScaler().fit(x_train)\n",
    "    x_train_std = std_scal.transform(x_train)\n",
    "\n",
    "\n",
    "    #主成分分析，通过求协方差矩阵的特征向量，利用特征向量构成的矩阵对原来的x进行转化-构成顺序按特征值大小逆序排序，转化后的特征数量是和x的特征数量相等的\n",
    "    sklearn_pca = sklearnPCA().fit(x_train_std)\n",
    "\n",
    "    #查看主成分分析后的个成分的方差信息，并且归一化\n",
    "    var_per = sklearn_pca.explained_variance_ratio_\n",
    "    cum_var_per = sklearn_pca.explained_variance_ratio_.cumsum()\n",
    "\n",
    "    l = len(cum_var_per[cum_var_per <= 0.7])\n",
    "    sklearn_pca = sklearnPCA(n_components=l).fit(x_train_std)\n",
    "\n",
    "    # 使用主成分分析的结果，对原特征进行较为\n",
    "    x_train = sklearn_pca.transform(x_train_std)\n",
    "    x_test = sklearn_pca.transform(std_scal.transform(x_test))\n",
    "    print('降维后的数据训练数据 shape：',x_train.shape)\n",
    "    print('降维后的测试数据shape: ',x_test.shape)\n",
    "\n",
    "    model = LogisticRegression(C=0.3,dual=False,max_iter=x_train.shape[0])\n",
    "    start_time = time.time()\n",
    "    model.fit(x_train , y_train)\n",
    "    print('fitting finished!')\n",
    "    end_time = time.time()\n",
    "    fit_time = end_time - start_time\n",
    "    print('time consumed of fitting:',show_time(fit_time))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    score = model.score(x_test, y_test)\n",
    "    end_time = time.time()\n",
    "    score_time = end_time-start_time\n",
    "    print('scoring finished!')\n",
    "    print('time consumed of scoring:',show_time(score_time))\n",
    "    print('test acc of logistics regression with PCA : ',score)\n",
    "\n",
    "    #查看混淆矩阵\n",
    "    print('打印混淆矩阵。。。。。。')\n",
    "    predicted = model.predict(sklearn_pca.transform(X))\n",
    "    print()\n",
    "    confusion_mtx = metrics.confusion_matrix(predicted, Y)\n",
    "    print(confusion_mtx)\n",
    "    # plot the confusion matrix\n",
    "    plot_confusion_matrix(confusion_mtx, classes=range(2)) \n",
    "lg_metrics_pca = logit_regresstion_with_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time  :  [1.0608108  1.05890656 1.08977151 1.05295706 1.01276183 1.05828977\n",
      " 1.067168  ]\n",
      "score_time  :  [0.03776169 0.03519988 0.03901458 0.03831244 0.03467798 0.03671265\n",
      " 0.03678727]\n",
      "test_score  :  [0.91351673 0.9148117  0.91232675 0.91414371 0.91617374 0.91246369\n",
      " 0.91533373]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "# 使用交叉验证对模型进行训练\n",
    "def logit_regresstion_with_crossvalidate(C=0.3):\n",
    "    x_train = X\n",
    "    pipe = make_pipeline(StandardScaler(),LogisticRegression(C=C,dual=False,max_iter=x_train.shape[0]))\n",
    "    metrics = model_selection.cross_validate(pipe,x_train,Y,cv=model_selection.KFold(n_splits=7))\n",
    "    for key,item in metrics.items():\n",
    "        print(key,' : ',item)\n",
    "logit_regresstion_with_crossvalidate(C=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.SVM --- Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time :  00:34:24\n",
      "score time :  600.2340214252472\n",
      "acc  is :  0.9019\n"
     ]
    }
   ],
   "source": [
    "# 下面使用SVM\n",
    "from sklearn.svm import SVC\n",
    "def svm(kernel = 'rbf',C=0.3):\n",
    "    model = SVC(C=C,kernel = kernel,random_state=42)\n",
    "\n",
    "    x_train,x_test,y_train,y_test = model_selection.train_test_split(X,Y,test_size=0.3,random_state=52)\n",
    "    pipe = make_pipeline(StandardScaler(),model)\n",
    "\n",
    "    start_time = time.time()\n",
    "    print('start to fit......')\n",
    "    pipe.fit(x_train,y_train)\n",
    "    end_time = time.time()\n",
    "    fit_time = end_time - start_time\n",
    "    print('fit time : ',show_time(fit_time))\n",
    "\n",
    "    start_time  = time.time()\n",
    "    score = pipe.score(x_test,y_test)\n",
    "    end_time = time.time()\n",
    "    score_time =  end_time-start_time\n",
    "    print('score time : ',show_time(score_time))\n",
    "    print('acc  is : ',score)\n",
    "    return [fit_time,score_time,score]\n",
    "svm_metrics = svm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "降维后的数据训练数据 shape： (140000, 137)\n",
      "降维后的测试数据shape:  (60000, 137)\n",
      "start to fit......\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8260/1957910982.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'acc  is : '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfit_time\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscore_time\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0msvm_metrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm_pca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8260/1957910982.py\u001b[0m in \u001b[0;36msvm_pca\u001b[1;34m(kernel, C)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'start to fit......'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mfit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mend_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python机器学习\\其他\\.venv\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"i\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python机器学习\\其他\\.venv\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    313\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_probB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_status_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m         \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibsvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 使用PCA降维后，再使用SVM\n",
    "from sklearn.svm import SVC\n",
    "def svm_pca(kernel = 'rbf',C=0.3):\n",
    "    model = SVC(C=C,kernel = kernel,random_state=42)\n",
    "\n",
    "    x_train,x_test,y_train,y_test = model_selection.train_test_split(X,Y,test_size=0.3,random_state=52)\n",
    "\n",
    "    #标准化\n",
    "    std_scal = StandardScaler().fit(x_train)\n",
    "    x_train_std = std_scal.transform(x_train)\n",
    "\n",
    "\n",
    "    #主成分分析，通过求协方差矩阵的特征向量，利用特征向量构成的矩阵对原来的x进行转化-构成顺序按特征值大小逆序排序，转化后的特征数量是和x的特征数量相等的\n",
    "    sklearn_pca = sklearnPCA().fit(x_train_std)\n",
    "\n",
    "    #查看主成分分析后的个成分的方差信息，并且归一化\n",
    "    var_per = sklearn_pca.explained_variance_ratio_\n",
    "    cum_var_per = sklearn_pca.explained_variance_ratio_.cumsum()\n",
    "\n",
    "    l = len(cum_var_per[cum_var_per <= 0.7])\n",
    "    sklearn_pca = sklearnPCA(n_components=l).fit(x_train_std)\n",
    "\n",
    "    # 使用主成分分析的结果，对原特征进行降维\n",
    "    x_train = sklearn_pca.transform(x_train_std)\n",
    "    x_test = sklearn_pca.transform(std_scal.transform(x_test))\n",
    "    print('降维后的数据训练数据 shape：',x_train.shape)\n",
    "    print('降维后的测试数据shape: ',x_test.shape)\n",
    "\n",
    "    pipe = model\n",
    "\n",
    "    start_time = time.time()\n",
    "    print('start to fit......')\n",
    "    pipe.fit(x_train,y_train)\n",
    "    end_time = time.time()\n",
    "    fit_time = end_time - start_time\n",
    "    print('fit time : ',show_time(fit_time))\n",
    "\n",
    "    start_time  = time.time()\n",
    "    score = pipe.score(x_test,y_test)\n",
    "    end_time = time.time()\n",
    "    score_time =  end_time-start_time\n",
    "    print('score time : ',score_time)\n",
    "    print('acc  is : ',score)\n",
    "    return [fit_time,score_time,score]\n",
    "svm_metrics = svm_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start to fit .............\n"
     ]
    }
   ],
   "source": [
    "# 先使用pca降维，再用交叉验证对SVM模型进行训练\n",
    "def svm_with_crossvalidate(C=0.3,kernel ='rbf'):\n",
    "\n",
    "    #标准化\n",
    "    std_scal = StandardScaler().fit(X)\n",
    "    x_train_std = std_scal.transform(X)\n",
    "\n",
    "    #主成分分析，通过求协方差矩阵的特征向量，利用特征向量构成的矩阵对原来的x进行转化-构成顺序按特征值大小逆序排序，转化后的特征数量是和x的特征数量相等的\n",
    "    sklearn_pca = sklearnPCA().fit(x_train_std)\n",
    "\n",
    "    #查看主成分分析后的个成分的方差信息，并且归一化\n",
    "    var_per = sklearn_pca.explained_variance_ratio_\n",
    "    cum_var_per = sklearn_pca.explained_variance_ratio_.cumsum()\n",
    "\n",
    "    l = len(cum_var_per[cum_var_per <= 0.7])\n",
    "    sklearn_pca = sklearnPCA(n_components=l).fit(x_train_std)\n",
    "    x_train= sklearn_pca.transform(x_train_std)\n",
    "\n",
    "    pipe = make_pipeline(StandardScaler(),SVC(C=C,kernel=kernel,random_state=52))\n",
    "    print('start to fit .............')\n",
    "    metrics = model_selection.cross_validate(pipe,x_train,Y,cv=model_selection.KFold(n_splits=7))\n",
    "    for key,item in metrics.items():\n",
    "        print(key,' : ',item)\n",
    "svm_with_crossvalidate(C=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. NN --- Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "降维后的数据训练数据 shape： (140000, 137)\n",
      "降维后的测试数据shape:  (60000, 137)\n",
      "start to fit......\n",
      "fit time :  00:00:34\n",
      "score time :  00:00:00\n",
      "acc  is :  0.9134\n"
     ]
    }
   ],
   "source": [
    "#使用MLP进行训练\n",
    "from sklearn import neural_network\n",
    "def nn_mlp(solver ='sgd',activation='logistic'):\n",
    "    model = neural_network.MLPClassifier(alpha=1e-5,  # 正则项的惩罚因子\n",
    "                                     hidden_layer_sizes=(80,),\n",
    "                                     # The solver for weight optimization.\n",
    "                                     solver=solver,\n",
    "                                     # ‘lbfgs’ is an optimizer in the family of quasi-Newton methods.\n",
    "                                     # ‘sgd’ refers to stochastic gradient descent.\n",
    "                                     # ‘adam’ refers to a stochastic gradient-based optimizer proposed by Kingma, Diederik, and Jimmy Ba\n",
    "                                     activation=activation,\n",
    "                                     # ‘identity’, no-op activation, useful to implement linear bottleneck, returns f(x) = x\n",
    "                                     # ‘logistic’, the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)).\n",
    "                                     # ‘tanh’, the hyperbolic tan function, returns f(x) = tanh(x).\n",
    "                                     # ‘relu’, the rectified linear unit function, returns f(x) = max(0, x)\n",
    "                                     random_state=52)\n",
    "    \n",
    "    x_train,x_test,y_train,y_test = model_selection.train_test_split(X,Y,test_size=0.3,random_state=52)\n",
    "\n",
    "    #标准化\n",
    "    std_scal = StandardScaler().fit(x_train)\n",
    "    x_train_std = std_scal.transform(x_train)\n",
    "\n",
    "\n",
    "    #主成分分析，通过求协方差矩阵的特征向量，利用特征向量构成的矩阵对原来的x进行转化-构成顺序按特征值大小逆序排序，转化后的特征数量是和x的特征数量相等的\n",
    "    sklearn_pca = sklearnPCA().fit(x_train_std)\n",
    "\n",
    "    #查看主成分分析后的个成分的方差信息，并且归一化\n",
    "    var_per = sklearn_pca.explained_variance_ratio_\n",
    "    cum_var_per = sklearn_pca.explained_variance_ratio_.cumsum()\n",
    "\n",
    "    l = len(cum_var_per[cum_var_per <= 0.7])\n",
    "    sklearn_pca = sklearnPCA(n_components=l).fit(x_train_std)\n",
    "\n",
    "    # 使用主成分分析的结果，对原特征进行降维\n",
    "    x_train = sklearn_pca.transform(x_train_std)\n",
    "    x_test = sklearn_pca.transform(std_scal.transform(x_test))\n",
    "    print('降维后的数据训练数据 shape：',x_train.shape)\n",
    "    print('降维后的测试数据shape: ',x_test.shape)\n",
    "\n",
    "    start_time = time.time()\n",
    "    print('start to fit......')\n",
    "    model.fit(x_train,y_train)\n",
    "    end_time = time.time()\n",
    "    fit_time = end_time - start_time\n",
    "    print('fit time : ',show_time(fit_time))\n",
    "\n",
    "    start_time  = time.time()\n",
    "    score = model.score(x_test,y_test)\n",
    "    end_time = time.time()\n",
    "    score_time =  end_time-start_time\n",
    "    print('score time : ',show_time(score_time))\n",
    "    print('acc  is : ',score)\n",
    "    return [fit_time,score_time,score]\n",
    "nn_mlp_metrics = nn_mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用CNN进行训练"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "99ae8d1c855da79370c0f19852a01459aa89d91f414e4084eab559d3968b050b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
