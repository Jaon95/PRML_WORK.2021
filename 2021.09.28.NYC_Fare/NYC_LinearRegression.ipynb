{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New York City Taxi Fare Prediction - Simple Linear Model\n",
    "This is a basic program for the New York City Taxi Fare Prediction.\n",
    "Here we'll use a simple linear model based on the travel vector from the taxi's pickup location to dropoff location which predicts the fare_amount of each ride.\n",
    "\n",
    "This kernel uses some pandas and mostly numpy for the critical work. There are many higher-level libraries you could use instead, for example sklearn or statsmodels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Python environment setup...\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # CSV file I/O (e.g. pd.read_csv)\n",
    "import os # reading the input files we have access to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup training data\n",
    "First let's read in our training data. Kernels do not yet support enough memory to load the whole dataset at once, at least using pd.read_csv. The entire dataset is about 55M rows, so we're skipping a good portion of the data, but it's certainly possible to build a model using all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key                   object\n",
       "fare_amount          float64\n",
       "pickup_datetime       object\n",
       "pickup_longitude     float64\n",
       "pickup_latitude      float64\n",
       "dropoff_longitude    float64\n",
       "dropoff_latitude     float64\n",
       "passenger_count        int64\n",
       "distance_miles       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df =  pd.read_csv('E:/NYC_Fare/train1.csv')\n",
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create two new features in our training set representing the \"travel vector\" between the start and end points of the taxi ride, in both longitude and latitude coordinates. We'll take the absolute value since we're only interested in distance traveled. Use a helper function since we'll want to do the same thing for the test set later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a dataframe, add two new features 'abs_diff_longitude' and\n",
    "# 'abs_diff_latitude' reprensenting the \"Manhattan vector\" from\n",
    "# the pickup location to the dropoff location.\n",
    "def add_travel_vector_features(df):\n",
    "    df['abs_diff_longitude'] = (df.dropoff_longitude - df.pickup_longitude).abs()\n",
    "    df['abs_diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\n",
    "\n",
    "add_travel_vector_features(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train our model\n",
    "Our model will take the form  Xâ‹…w=y where  X is a matrix of input features, and  y  is a column of the target variable,  fare_amount, for each row. The weight column  w is what we will \"learn\".\n",
    "\n",
    "First let's setup our input matrix  X and target column  y  from our training set. The matrix  X should consist of the two GPS coordinate differences, plus a third term of 1 to allow the model to learn a constant bias term. The column  y should consist of the target fare_amount values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(195767, 3)\n",
      "(195767,)\n"
     ]
    }
   ],
   "source": [
    "# Construct and return an Nx3 input matrix for our linear model\n",
    "# using the travel vector, plus a 1.0 for a constant bias term.\n",
    "def get_input_matrix(df):\n",
    "    return np.column_stack((df.abs_diff_longitude, df.abs_diff_latitude, np.ones(len(df))))\n",
    "\n",
    "train_X = get_input_matrix(train_df)\n",
    "train_y = np.array(train_df['fare_amount'])\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[164.4579912  112.90727954   5.15986424]\n"
     ]
    }
   ],
   "source": [
    "# The lstsq function returns several things, and we only care about the actual weight vector w.\n",
    "(w, _, _, _) = np.linalg.lstsq(train_X, train_y, rcond = None)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These weights pass a quick sanity check, since we'd expect the first two values -- the weights for the absolute longitude and latitude differences -- to be positive, as more distance should imply a higher fare, and we'd expect the bias term to loosely represent the cost of a very short ride.\n",
    "\n",
    "Sidenote: we can actually calculate the weight column  w  directly using the Ordinary Least Squares method: \n",
    "$w = (X^T \\cdot X)^{-1} \\cdot X^T \\cdot y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[164.4579912  112.90727954   5.15986424]\n"
     ]
    }
   ],
   "source": [
    "w_OLS = np.matmul(np.matmul(np.linalg.inv(np.matmul(train_X.T, train_X)), train_X.T), train_y)\n",
    "print(w_OLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions on the test set\n",
    "Now let's load up our test inputs and predict the fare_amounts for them using our learned weights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key                   object\n",
       "pickup_datetime       object\n",
       "pickup_longitude     float64\n",
       "pickup_latitude      float64\n",
       "dropoff_longitude    float64\n",
       "dropoff_latitude     float64\n",
       "passenger_count        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('E:/NYC_Fare/test1.csv')\n",
    "test_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reuse the above helper functions to add our features and generate the input matrix.\n",
    "add_travel_vector_features(test_df)\n",
    "test_X = get_input_matrix(test_df)\n",
    "# Predict fare_amount on the test set using our model (w) trained on the training set.\n",
    "test_y_predictions = np.matmul(test_X, w).round(decimals = 2)\n",
    "\n",
    "# Write the predictions to a CSV file which we can submit to the competition.\n",
    "submission = pd.DataFrame(\n",
    "    {'key': test_df.key, 'fare_amount': test_y_predictions},\n",
    "    columns = ['key', 'fare_amount'])\n",
    "submission.to_csv('E:/NYC_Fare/prediction1.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas for Improvement\n",
    "The output here will score an RMSE of $5.74, but you can do better than that! Here are some suggestions:\n",
    "\n",
    "Use more columns from the input data. Here we're only using the start/end GPS points from columns [pickup|dropoff]_[latitude|longitude]. Try to see if the other columns -- pickup_datetime and passenger_count -- can help improve your results.\n",
    "Use absolute location data rather than relative. Here we're only looking at the difference between the start and end points, but maybe the actual values -- indicating where in NYC the taxi is traveling -- would be useful.\n",
    "Use a non-linear model to capture more intricacies within the data.\n",
    "Try to find more outliers to prune, or construct useful feature crosses.\n",
    "Use the entire dataset -- here we're only using about 20% of the training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth = pd.read_csv('E:/NYC_Fare/value1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9810, 2)\n",
      "(9810, 2)\n"
     ]
    }
   ],
   "source": [
    "print(groundtruth.shape)\n",
    "print(submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9810 9810\n"
     ]
    }
   ],
   "source": [
    "trueArray = np.array(groundtruth['fare_amount'])\n",
    "predArray = np.array(submission['fare_amount'])\n",
    "print(len(trueArray),len(predArray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.416984327495839\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(np.mean(np.square(trueArray-predArray)))\n",
    "print(rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
